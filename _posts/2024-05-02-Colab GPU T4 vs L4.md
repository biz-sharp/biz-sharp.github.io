---
layout: post
title:  "구글 Colab GPU 비교 - T4 vs L4"
---

# 구글 Colab GPU 비교 - T4 vs L4



여기 Colab GPU 기능 및 가격 요약표입니다:

| GPU 모델 | 아키텍처         | 출시일       | VRAM   | 단위/시간    | 비용/시간 | 10달러 사용 시간 |
| ------ | ------------ | --------- | ------ | -------- | ----- | ---------- |
| **T4** | Turing       | 2018.9.13 | 15GB   | 1.84 단위  | $0.18 | 54시간 20분   |
| V100   | Volta        | 2017.6.21 | 16GB   | 4.91 단위  | $0.49 | 20시간 21분   |
| **L4** | Ada Lovelace | 2023.3.21 | 22.5GB | 4.82 단위  | $0.48 | 20시간 47분   |
| A100   | Ampere       | 2020.5.14 | 40GB   | 11.77 단위 | $1.18 | 8시간 30분    |

주요 내용:

- Colab은 여전히 T4 GPU를 무료로 제공하고 있습니다.
- 유료 GPU 옵션은 비용 대비 효과적일 수 있습니다. A100은 비싸지만 속도가 13배 빠릅니다.
  
  

**T4 GPU:**

- 아키텍처: 튜링(Turing)
- VRAM: 16GB 중 **<u>15GB만 사용 가능</u>** (1GB는 오류 수정 코드를 위해 사용)
- 성능: **<u>65 Teraflops (FP16 정밀도)</u>**
- 특징:
  - FlashAttention v2는 지원되지 않지만, sdpa(squared dot product attention)는 기본적으로 지원됨
  - bfloat16 지원 안됨. 이로 인해 수치 불안정성 문제 발생 가능
  - <u>현재 Colab에서 완전 무료로 사용 가능</u>
  - 긴 시퀀스 길이(1024)와 큰 배치 사이즈(4)에서는 메모리 부족으로 성능 저하
  - <u>작은 작업에서는 비용 효율적</u>

**L4 GPU:**

- 아키텍처: 아다 로벨레이스(Ada Lovelace)
- VRAM: **<u>22.5GB</u>**
- 성능: **<u>121 Teraflops (FP16 정밀도), T4 대비 약 2.8배 빠름</u>**
- 특징:
  - bfloat16 지원
  - 메모리가 T4보다 크므로 긴 시퀀스 길이/큰 배치 사이즈 작업 가능
  - <u>비용은 시간당 $0.48로 T4보다 높지만 성능 향상으로 비용 효율적</u>

요약하면, L4는 T4보다 성능과 메모리 측면에서 향상되었지만, 비용도 높아졌습니다. 

작업 요구사항에 따라 적절한 GPU를 선택하는 것이 중요합니다.
